# Open-LLM-VTuber Fork  
https://github.com/martysl/shapes-vtuber

## âœ¨ Reason why
- This is fork of [Open-LLM-VTuber](https://github.com/Open-LLM-VTuber/Open-LLM-VTuber) to made it work with shapes.inc!
### What Changed
- To add chat bridge function (by Marty)
- vtuber_chat_bridge.py to wotk chat form YT, Twitch, bilibili and irc (in progress) (by Marty)
- basic memory and  llm connector (by Marty)

### ğŸ‘€ Demo
| ![](assets/i1.jpg) | ![](assets/i2.jpg) |
|:---:|:---:|
| ![](assets/i3.jpg) | ![](assets/i4.jpg) |
[![Watch the video](https://img.youtube.com/vi/e30IFkNX0mY/0.jpg)](https://www.youtube.com/watch?v=e30IFkNX0mY)

## âœ¨ TODO
- fix file vtuber_chat_bridge.py and proxy (where needed)
- everything else not mentioned

## âœ¨ Features & Highlights
- ğŸ–¥ï¸ **Cross-platform support**: Perfect compatibility with macOS, Linux, and Windows. We support NVIDIA and non-NVIDIA GPUs, with options to run on CPU or use cloud APIs for resource-intensive tasks. Some components support GPU acceleration on macOS.

- ğŸ”’ **Offline mode support**: Run completely offline using local models - no internet required. Your conversations stay on your device, ensuring privacy and security.

- ğŸ’» **Attractive and powerful web and desktop clients**: Offers both web version and desktop client usage modes, supporting rich interactive features and personalization settings. The desktop client can switch freely between window mode and desktop pet mode, allowing the AI companion to be by your side at all times.

- ğŸ¯ **Advanced interaction features**:
  - ğŸ‘ï¸ Visual perception, supporting camera, screen recording and screenshots, allowing your AI companion to see you and your screen
  - ğŸ¤ Voice interruption without headphones (AI won't hear its own voice)
  - ğŸ«± Touch feedback, interact with your AI companion through clicks or drags
  - ğŸ˜Š Live2D expressions, set emotion mapping to control model expressions from the backend
  - ğŸ± Pet mode, supporting transparent background, global top-most, and mouse click-through - drag your AI companion anywhere on the screen
  - ğŸ’­ Display AI's inner thoughts, allowing you to see AI's expressions, thoughts and actions without them being spoken
  - ğŸ—£ï¸ AI proactive speaking feature
  - ğŸ’¾ Chat log persistence, switch to previous conversations anytime
  - ğŸŒ TTS translation support (e.g., chat in Chinese while AI uses Japanese voice)

- ğŸ§  **Extensive model support**:
  - ğŸ¤– Large Language Models (LLM): Ollama, OpenAI (and any OpenAI-compatible API), Gemini, Claude, Mistral, DeepSeek, Zhipu AI, GGUF, LM Studio, vLLM, etc.
  - ğŸ™ï¸ Automatic Speech Recognition (ASR): sherpa-onnx, FunASR, Faster-Whisper, Whisper.cpp, Whisper, Groq Whisper, Azure ASR, etc.
  - ğŸ”Š Text-to-Speech (TTS): sherpa-onnx, pyttsx3, MeloTTS, Coqui-TTS, GPTSoVITS, Bark, CosyVoice, Edge TTS, Fish Audio, Azure TTS, etc.

- ğŸ”§ **Highly customizable**:
  - âš™ï¸ **Simple module configuration**: Switch various functional modules through simple configuration file modifications, without delving into the code
  - ğŸ¨ **Character customization**: Import custom Live2D models to give your AI companion a unique appearance. Shape your AI companion's persona by modifying the Prompt. Perform voice cloning to give your AI companion the voice you desire
  - ğŸ§© **Flexible Agent implementation**: Inherit and implement the Agent interface to integrate any Agent architecture, such as HumeAI EVI, OpenAI Her, Mem0, etc.
  - ğŸ”Œ **Good extensibility**: Modular design allows you to easily add your own LLM, ASR, TTS, and other module implementations, extending new features at any time


## ğŸš€ Quick Start

Please refer to the [Quick Start](https://open-llm-vtuber.github.io/docs/quick-start) section in our documentation for installation.
This is just for to work with shapes.inc, i own only my changes, for everything else look under:

# ğŸ‰ğŸ‰ğŸ‰ Original repo

![](./assets/banner.jpg)

Thanks to [Open-LLM-VTuber](https://github.com/Open-LLM-VTuber/Open-LLM-VTuber)  
Their Discord:  
[![](https://dcbadge.limes.pink/api/server/3UDA8YFDXx)](https://discord.gg/3UDA8YFDXx)

## ğŸ“œ Third-Party Licenses

### Live2D Sample Models Notice

This project includes Live2D sample models provided by Live2D Inc. These assets are licensed separately under the Live2D Free Material License Agreement and the Terms of Use for Live2D Cubism Sample Data. They are not covered by the MIT license of this project.

This content uses sample data owned and copyrighted by Live2D Inc. The sample data are utilized in accordance with the terms and conditions set by Live2D Inc. (See [Live2D Free Material License Agreement](https://www.live2d.jp/en/terms/live2d-free-material-license-agreement/) and [Terms of Use](https://www.live2d.com/eula/live2d-sample-model-terms_en.html)).

Note: For commercial use, especially by medium or large-scale enterprises, the use of these Live2D sample models may be subject to additional licensing requirements. If you plan to use this project commercially, please ensure that you have the appropriate permissions from Live2D Inc., or use versions of the project without these models.





